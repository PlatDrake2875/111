{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PlatDrake2875/111/blob/main/Hackathon_SIE_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA9M1gpwU9ET"
      },
      "source": [
        "# Download Masked Face Recognition model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8k-YbYvGObY",
        "outputId": "5dbc180a-7aff-4b0a-e143-eb40891ac7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.2)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.23-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.23-py3-none-any.whl (877 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m877.6/877.6 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.23 ultralytics-thop-2.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install matplotlib numpy opencv-python pillow\n",
        "!pip install pyyaml\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NzakTc-2tqJ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cd3JIjqU6O_"
      },
      "source": [
        "# Connect to Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmCjeNWdGYnJ",
        "outputId": "6fe99701-b3e2-4497-9053-0cee3235da62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-zXQ9mpU8bG",
        "outputId": "ac7a0d10-9d66-4c36-df3a-d3a52682b1d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ReadME.MD',\n",
              " 'db',\n",
              " 'hackaton_wild_ds',\n",
              " 'test',\n",
              " 'Modified',\n",
              " 'YOLO',\n",
              " 'Detection_Results',\n",
              " 'test_images',\n",
              " 'timer.py',\n",
              " 'faces_dataset',\n",
              " 'dataset_face_cropped']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "hack_sie_path = '/content/drive/My Drive/Hack_SIE_2024'\n",
        "os.listdir(hack_sie_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMR9NFllsSE-"
      },
      "source": [
        "# Procesare de Date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leT-KKz7sJGP",
        "outputId": "6d9ecaa0-ba2f-4f69-9b35-8282af901dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Andres', 'Ester', 'DaniF', 'Isa', 'Dani B', 'Cristina', 'Diego', 'Marcos', 'Narciso', 'Pablo']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def get_db():\n",
        "    input_folder = os.path.join(hack_sie_path, 'db')\n",
        "    output_folder = os.path.join(hack_sie_path, 'Modified')\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    person_folders = os.listdir(input_folder)\n",
        "    print(person_folders)\n",
        "\n",
        "    for person_id, person_folder in enumerate(person_folders, start=1):\n",
        "        person_path = os.path.join(input_folder, person_folder)\n",
        "\n",
        "        if os.path.isdir(person_path):\n",
        "            images = os.listdir(person_path)\n",
        "\n",
        "            for image in images:\n",
        "                if 'Indoor' in image and 'M' in image:\n",
        "                    new_name = f\"{person_id}_IM.jpg\"\n",
        "                elif 'Indoor' in image:\n",
        "                    new_name = f\"{person_id}_I.jpg\"\n",
        "                elif 'Outdoor' in image and 'M' in image:\n",
        "                    new_name = f\"{person_id}_OM.jpg\"\n",
        "                elif 'Outdoor' in image:\n",
        "                    new_name = f\"{person_id}_O.jpg\"\n",
        "                else:\n",
        "                    new_name = image\n",
        "\n",
        "                old_file_path = os.path.join(person_path, image)\n",
        "                new_file_path = os.path.join(output_folder, new_name)\n",
        "\n",
        "                shutil.copy2(old_file_path, new_file_path)\n",
        "\n",
        "    # print(\"Pozele au fost redenumite și salvate în folderul modificat.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7GuglT3sUwS"
      },
      "source": [
        "# Antrenarea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJDLFgxGFgnP"
      },
      "source": [
        "# Face detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUP-o3-wQUZZ",
        "outputId": "bda2e179-7a8d-4437-b831-eaa93828fb75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "--2024-10-25 20:44:00--  https://github.com/akanametov/yolo-face/releases/download/v0.0.0/yolov11n-face.pt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/592261808/fc8c7e89-5eff-4ce4-a539-7d7a62fb9e4f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241025%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241025T204400Z&X-Amz-Expires=300&X-Amz-Signature=47c5ebd27a8e1689225bf60592c1fdd1328fe5db55c96347a3d4823c03588440&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov11n-face.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-10-25 20:44:00--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/592261808/fc8c7e89-5eff-4ce4-a539-7d7a62fb9e4f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241025%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241025T204400Z&X-Amz-Expires=300&X-Amz-Signature=47c5ebd27a8e1689225bf60592c1fdd1328fe5db55c96347a3d4823c03588440&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov11n-face.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5455955 (5.2M) [application/octet-stream]\n",
            "Saving to: ‘yolov11n-face.pt’\n",
            "\n",
            "yolov11n-face.pt    100%[===================>]   5.20M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-10-25 20:44:00 (60.6 MB/s) - ‘yolov11n-face.pt’ saved [5455955/5455955]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "\n",
        "# Download the YOLOv8 face detection model\n",
        "!wget https://github.com/akanametov/yolo-face/releases/download/v0.0.0/yolov11n-face.pt\n",
        "\n",
        "model = YOLO('yolov11n-face.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT8EjliDQVKd"
      },
      "outputs": [],
      "source": [
        "modified_folder = output_folder\n",
        "\n",
        "image_files = [f for f in os.listdir(modified_folder) if f.lower().endswith(('.jpg'))]\n",
        "\n",
        "print(\"Processing images:\", image_files)\n",
        "\n",
        "# Create an output directory for the results\n",
        "results_folder = os.path.join(hack_sie_path, 'Detection_Results')\n",
        "if not os.path.exists(results_folder):\n",
        "    os.makedirs(results_folder)\n",
        "\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(modified_folder, image_file)\n",
        "\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Check if image was loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image {image_file}\")\n",
        "        continue\n",
        "\n",
        "    # Perform face detection\n",
        "    results = model.predict(source=img, save=False, imgsz=640)\n",
        "\n",
        "    # Extract detection results\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
        "    confs = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
        "\n",
        "    # Draw bounding boxes on the image\n",
        "    for i in range(len(boxes)):\n",
        "        x1, y1, x2, y2 = boxes[i].astype(int)\n",
        "        conf = confs[i]\n",
        "\n",
        "        # Draw the bounding box\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Put the confidence score label\n",
        "        label = f\"Face {conf:.2f}\"\n",
        "        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Save the image to the results folder\n",
        "    result_image_path = os.path.join(results_folder, image_file)\n",
        "    cv2.imwrite(result_image_path, img)\n",
        "\n",
        "    # Convert BGR to RGB for display\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Display the image\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.title(f\"Detections in {image_file}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Detection results have been saved to the 'Detection_Results' folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test images extractor"
      ],
      "metadata": {
        "id": "vfqPIEYjtAau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Initialize an empty dictionary for name-to-ID mapping\n",
        "name_to_id = {}\n",
        "current_id = 1  # Start ID from 1\n",
        "\n",
        "# Mapping for location encoding\n",
        "location_encoding = {\n",
        "    'Indoor': 'I',\n",
        "    'Outdoor': 'O'\n",
        "}\n",
        "\n",
        "# Mapping for mask state encoding\n",
        "mask_state_encoding = {\n",
        "    'Masked': 'M',\n",
        "    'Non-masked': 'UN'\n",
        "}\n",
        "\n",
        "def process_image(person_file, current_path, destination_folder, location, mask_state, name_to_id, current_id):\n",
        "    if person_file.endswith('.png'):\n",
        "        person_path = os.path.join(current_path, person_file)\n",
        "\n",
        "        # Extract person name and image index correctly\n",
        "        parts = person_file.split(' - ')\n",
        "        person_name = parts[0]\n",
        "        img_index = parts[-1]  # Last part is the image index (e.g., M3C.png)\n",
        "\n",
        "        # Assign ID to the person if not already assigned\n",
        "        if person_name not in name_to_id:\n",
        "            name_to_id[person_name] = current_id\n",
        "            current_id += 1\n",
        "\n",
        "        # Get the person's ID from the dictionary\n",
        "        person_id = name_to_id[person_name]\n",
        "\n",
        "        # Encode location (I for Indoor, O for Outdoor)\n",
        "        location_code = location_encoding.get(location, location)\n",
        "\n",
        "        # Encode mask state (M for Masked, UN for Non-masked)\n",
        "        mask_state_code = mask_state_encoding.get(mask_state, mask_state)\n",
        "\n",
        "        # Construct the new file name using the ID, location encoding, and mask state encoding\n",
        "        new_file_name = f'{person_id}_{location_code}_{mask_state_code}_{img_index}'\n",
        "\n",
        "        # Ensure the destination folder exists\n",
        "        if not os.path.exists(destination_folder):\n",
        "            os.makedirs(destination_folder)\n",
        "\n",
        "        # Define the new file path in the destination folder\n",
        "        new_file_path = os.path.join(destination_folder, new_file_name)\n",
        "\n",
        "        # Copy the file to the destination with the new name\n",
        "        shutil.copy(person_path, new_file_path)\n",
        "\n",
        "    return current_id  # Return updated current ID\n",
        "\n",
        "def main(hack_sie_path):\n",
        "    source_folder = os.path.join(hack_sie_path, 'test')\n",
        "    destination_folder = os.path.join(hack_sie_path, 'test_images')\n",
        "\n",
        "    if not os.path.exists(destination_folder):\n",
        "        os.makedirs(destination_folder)\n",
        "\n",
        "    categories = {\n",
        "        'Indoor': ['Masked', 'Non-masked'],\n",
        "        'Outdoor': ['Masked', 'Non-masked']\n",
        "    }\n",
        "\n",
        "    global current_id\n",
        "\n",
        "    # Using ThreadPoolExecutor to process files in parallel\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        for location, mask_states in categories.items():\n",
        "            for mask_state in mask_states:\n",
        "                current_path = os.path.join(source_folder, location, mask_state)\n",
        "\n",
        "                # Submit tasks to the thread pool\n",
        "                for person_file in os.listdir(current_path):\n",
        "                    current_id = executor.submit(process_image, person_file, current_path, destination_folder, location, mask_state, name_to_id, current_id).result()\n",
        "\n",
        "    print(\"Image processing completed.\")\n",
        "    print(\"Name to ID mapping:\", name_to_id)\n",
        "\n",
        "main(hack_sie_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TK7J2Tj-tDs_",
        "outputId": "048b2e8f-71a5-43df-e337-3446d023591b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image processing completed.\n",
            "Name to ID mapping: {'Andres': 1, 'Cristina': 2, 'DaniB': 3, 'DaniF': 4, 'Diego': 5, 'Ester': 6, 'Iacob': 7, 'Isa': 8, 'Narciso': 9, 'Pablo': 10, 'Marcos': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ArcFace Dataset"
      ],
      "metadata": {
        "id": "LsVtw2jh8lVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "model = YOLO('yolov11n-face.pt')\n",
        "\n",
        "def extract_faces(image, boxes):\n",
        "    faces = []\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        face = image[y1:y2, x1:x2]\n",
        "        faces.append(face)\n",
        "    return faces\n",
        "\n",
        "def process_image(image_path, output_folder, original_name):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Failed to load image {image_path}\")\n",
        "        return\n",
        "\n",
        "    results = model.predict(source=img, save=False, imgsz=640)\n",
        "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
        "\n",
        "    faces = extract_faces(img, boxes)\n",
        "\n",
        "    for i, face in enumerate(faces):\n",
        "        output_path = os.path.join(output_folder, original_name)\n",
        "        cv2.imwrite(output_path, face)\n",
        "\n",
        "def main(root_folder, output_root_folder):\n",
        "    for person_folder in os.listdir(root_folder):\n",
        "        person_folder_path = os.path.join(root_folder, person_folder)\n",
        "        output_person_folder_path = os.path.join(output_root_folder, person_folder)\n",
        "\n",
        "        if os.path.isdir(person_folder_path):\n",
        "            if not os.path.exists(output_person_folder_path):\n",
        "                os.makedirs(output_person_folder_path)\n",
        "\n",
        "            image_files = [f for f in os.listdir(person_folder_path) if f.lower().endswith(('.jpg', '.png'))]\n",
        "            for image_file in image_files:\n",
        "                image_path = os.path.join(person_folder_path, image_file)\n",
        "                process_image(image_path, output_person_folder_path, image_file)\n",
        "\n",
        "root_folder = os.path.join(hack_sie_path, 'faces_dataset')\n",
        "output_root_folder = os.path.join(hack_sie_path, 'dataset_face_cropped')\n",
        "\n",
        "main(root_folder, output_root_folder)"
      ],
      "metadata": {
        "id": "zrmigw1axEjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arc Data compilation\n",
        "\n"
      ],
      "metadata": {
        "id": "Ej51-dgVbYNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deepinsight/insightface.git $hack_sie_path/insightface\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTyKz6Y5k7TR",
        "outputId": "f77383da-6aea-4dce-ef1e-81466fc36c61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/hack_sie_2024/insightface' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd $hack_sie_path/insightface/recognition/arcface_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1ndObsTlLW2",
        "outputId": "99e73cbe-a709-4faa-8b91-7d69a167e6e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace `sklearn` with `scikit-learn` in the requirements file\n",
        "!sed -i 's/^sklearn/scikit-learn/' /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt\n",
        "!pip install -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zge5TJv6lObJ",
        "outputId": "f6f71ad4-ff5f-437e-d115-ff7b8115a4cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (2.17.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 2)) (1.13)\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (1.9.1)\n",
            "Collecting onnx (from -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 4))\n",
            "  Using cached onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 5)) (1.5.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 6)) (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 5)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r /content/drive/MyDrive/hack_sie_2024/insightface/recognition/arcface_torch/requirement.txt (line 1)) (3.0.2)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config the Config File"
      ],
      "metadata": {
        "id": "zXgMW9FAmIu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "# Define the hack_sie_path\n",
        "hack_sie_path = \"/content/drive/MyDrive/Hack_SIE_2024\"\n",
        "\n",
        "# Define the config file path\n",
        "config_path = f\"{hack_sie_path}/configs/train_config.yaml\"\n",
        "\n",
        "# Configuration setup\n",
        "config = {\n",
        "    \"dataset\": {\n",
        "        \"train_dataset\": f\"{hack_sie_path}/dataset_face_cropped\",\n",
        "        \"num_classes\": 11,\n",
        "        \"input_size\": 1000,\n",
        "        \"batch_size\": 32,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"backbone\": \"r50\",  # ResNet-50 as backbone\n",
        "        \"embedding_size\": 512,\n",
        "        \"num_features\": 512,\n",
        "    },\n",
        "    \"optimizer\": {\n",
        "        \"lr\": 0.1,\n",
        "        \"momentum\": 0.9,\n",
        "        \"weight_decay\": 5e-4,\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"epochs\": 20,\n",
        "        \"gpus\": 1,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Ensure the configs directory exists\n",
        "os.makedirs(f\"{hack_sie_path}/configs\", exist_ok=True)\n",
        "\n",
        "# Write the config to a YAML file\n",
        "try:\n",
        "    with open(config_path, 'w') as file:\n",
        "        yaml.dump(config, file)\n",
        "        print(f\"Configuration file successfully created at {config_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to write configuration file: {e}\")\n",
        "\n",
        "# Double-check file content\n",
        "if os.path.exists(config_path):\n",
        "    print(\"YAML file content:\")\n",
        "    with open(config_path, 'r') as file:\n",
        "        print(file.read())\n",
        "else:\n",
        "    print(\"The YAML file does not exist.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUzsgYjLlgpi",
        "outputId": "d65ef23b-e322-44ba-bb97-78bc97f15cad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration file successfully created at /content/drive/MyDrive/Hack_SIE_2024/configs/train_config.yaml\n",
            "YAML file content:\n",
            "dataset:\n",
            "  batch_size: 32\n",
            "  input_size: 1000\n",
            "  num_classes: 11\n",
            "  train_dataset: /content/drive/MyDrive/Hack_SIE_2024/dataset_face_cropped\n",
            "model:\n",
            "  backbone: r50\n",
            "  embedding_size: 512\n",
            "  num_features: 512\n",
            "optimizer:\n",
            "  lr: 0.1\n",
            "  momentum: 0.9\n",
            "  weight_decay: 0.0005\n",
            "training:\n",
            "  epochs: 20\n",
            "  gpus: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace np.bool with np.bool_ across the entire mxnet package\n",
        "!find /usr/local/lib/python3.10/dist-packages/mxnet/ -type f -exec sed -i 's/np.bool/np.bool_/g' {} +"
      ],
      "metadata": {
        "id": "8gaQ9m7WnhBW"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_v2.py {hack_sie_path}/configs/config.yaml"
      ],
      "metadata": {
        "id": "MkVH_sKcnEYe"
      },
      "execution_count": 39,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}